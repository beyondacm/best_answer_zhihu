{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "import re\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features From Test_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_normal_features(path_in, path_normal):\n",
    "    \n",
    "    raw_data = pd.read_csv(path_in)\n",
    "    \n",
    "    # feature1 : num of words in answer_content\n",
    "    answer_content = raw_data['txt_content']\n",
    "    answer_content = answer_content.str.split(\" +\")\n",
    "    f1 = answer_content.str.len()\n",
    "    \n",
    "    # feature2 : num of words in question_content\n",
    "    question_content = raw_data['title']\n",
    "    question_content = question_content.str.split(\" +\")\n",
    "    f2 = question_content.str.len()\n",
    "    \n",
    "    # feature3 : num of question tags \n",
    "    question_tags = raw_data['tag']\n",
    "    question_tags = question_tags.str.split(\" +\")\n",
    "    f3 = question_tags.str.len()\n",
    "    \n",
    "    # feature4 : num of answers \n",
    "    numOfAnswers = raw_data['n_ans_x']\n",
    "    f4 = numOfAnswers\n",
    "    \n",
    "    # feature5 : num of agrees of user \n",
    "    numOfAgrees = raw_data['n_agree']\n",
    "    f5 = numOfAgrees\n",
    "    \n",
    "    # feature6 : num of ans_y of user\n",
    "    numOfAnsY = raw_data['n_ans_y']\n",
    "    f6 = numOfAnsY\n",
    "    \n",
    "    # feature7 : num of Articles of user\n",
    "    numOfArticle = raw_data['n_article']\n",
    "    f7 = numOfArticle\n",
    "    \n",
    "    # feature8 : num of Ask of user \n",
    "    numOfAsk = raw_data['n_ask']\n",
    "    f8 = numOfAsk\n",
    "    \n",
    "    # feature9 : num of Collection of user\n",
    "    numOfCollection = raw_data['n_collection']\n",
    "    f9 = numOfCollection\n",
    "    \n",
    "    # feature10 : num of edit log of user\n",
    "    numOfEditLog = raw_data['n_editlog']\n",
    "    f10 = numOfEditLog\n",
    "    \n",
    "    # feature11 : num of follower of user\n",
    "    numOfFollower = raw_data['n_follower']\n",
    "    f11 = numOfFollower\n",
    "    \n",
    "    # feature12 : num of thanks of user\n",
    "    numOfThanks = raw_data['n_thanks']\n",
    "    f12 = numOfThanks\n",
    "    \n",
    "    # feature13 : num of topic of user\n",
    "    numOfTopic = raw_data['n_topic']\n",
    "    f13 = numOfTopic\n",
    "    \n",
    "    # feature14 : num of followee of user \n",
    "    numOfFollowee = raw_data['n_followee']\n",
    "    f14 = numOfFollowee\n",
    "    \n",
    "    f1.to_csv(path_normal+'/f1.txt')\n",
    "    f2.to_csv(path_normal+'/f2.txt')\n",
    "    f3.to_csv(path_normal+'/f3.txt')\n",
    "    f4.to_csv(path_normal+'/f4.txt')\n",
    "    f5.to_csv(path_normal+'/f5.txt')\n",
    "    f6.to_csv(path_normal+'/f6.txt')\n",
    "    f7.to_csv(path_normal+'/f7.txt')\n",
    "    f8.to_csv(path_normal+'/f8.txt')\n",
    "    f9.to_csv(path_normal+'/f9.txt')\n",
    "    f10.to_csv(path_normal+'/f10.txt')\n",
    "    f11.to_csv(path_normal+'/f11.txt')\n",
    "    f12.to_csv(path_normal+'/f12.txt')\n",
    "    f13.to_csv(path_normal+'/f13.txt')\n",
    "    f14.to_csv(path_normal+'/f14.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_text_features(path_in, path_text):\n",
    "    \n",
    "    raw_data = pd.read_csv(path_in)\n",
    "\n",
    "    # Process with the question_content\n",
    "    question_content = raw_data['title']\n",
    "    question_content.to_csv(path_text+'/question_content.txt', encoding='utf-8', index = False)\n",
    "\n",
    "    # Process with the answer_content\n",
    "    answer_content = raw_data['txt_content']\n",
    "    answer_content.to_csv(path_text+'/answer_content.txt', encoding='utf-8', index = False)\n",
    "\n",
    "    # Process with question_tags\n",
    "    question_tags = raw_data['tag']\n",
    "    question_tags.to_csv(path_text+'/question_tags.txt', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "\n",
    "def unique(a):\n",
    "    return list(set(a))\n",
    "\n",
    "def intersect(a,b):\n",
    "    return list(set(a)&set(b))\n",
    "\n",
    "def union(a,b):\n",
    "    return list(set(a) | set(b))\n",
    "\n",
    "def write_overlap_file(fout, overlap_list, count):\n",
    "    num_overlap = len(overlap_list) \n",
    "    fout.write(str(count)+',')\n",
    "    fout.write(' '.join(overlap_list))\n",
    "    fout.write(','+str(num_overlap)+'\\n')   \n",
    "\n",
    "    \n",
    "# Run this code for best_answer_features\n",
    "# PATH_IN = 'DIVIDE/match/best_answer_features/OVER_LAP/'\n",
    "# PATH_OUT = 'DIVIDE/match/best_answer_features/OVER_LAP/'\n",
    "# PATH_FEATURES = 'DIVIDE/match/best_answer_features/'\n",
    "\n",
    "def extract_overlap_features(PATH_TEXT, PATH_OVERLAP, PATH_NORMAL) :\n",
    "\n",
    "    f15 = open(PATH_NORMAL + 'f15.txt', 'w')\n",
    "    f16 = open(PATH_NORMAL + 'f16.txt', 'w')\n",
    "   \n",
    "    with open(PATH_TEXT + 'answer_content.txt' , 'r') as fin_1, \\\n",
    "        open(PATH_TEXT + 'question_content.txt', 'r') as fin_2, \\\n",
    "        open(PATH_TEXT + 'question_tags.txt' , 'r') as fin_3, \\\n",
    "        open(PATH_OVERLAP + 'answerContent_questionContent.txt', 'w') as fout_1, \\\n",
    "        open(PATH_OVERLAP + 'answerContent_questionTags.txt', 'w') as fout_2 :\n",
    "            \n",
    "            count = 0\n",
    "\n",
    "            for line1, line2, line3 in izip( fin_1, fin_2, fin_3 ):\n",
    "                # answer_content\n",
    "                word_list1 = line1.strip().split(\" \")\n",
    "                # question_content\n",
    "                word_list2 = line2.strip().split(\" \")\n",
    "                # question_tags\n",
    "                word_list3 = line3.strip().split(\" \")\n",
    "                \n",
    "                # answer_content & question_content\n",
    "                over_lap1 = intersect(word_list1, word_list2)\n",
    "                # answer_content & question_tags\n",
    "                over_lap2 = intersect(word_list1, word_list3)\n",
    "                \n",
    "                write_overlap_file(fout_1, over_lap1, count)\n",
    "                write_overlap_file(fout_2, over_lap2, count)\n",
    "                \n",
    "                # overlap features : answer_content & question_content overlap\n",
    "                f15.write(str(count) + ',' + str( len(over_lap1) ) + '\\n') \n",
    "                # overalp features : answer_content & question_tags overlap\n",
    "                f16.write(str(count) + ',' + str( len(over_lap2) ) + '\\n')\n",
    "                \n",
    "                count = count + 1\n",
    "    \n",
    "    f15.close()\n",
    "    f16.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lda_source(PATH_IN, PATH_LDA) :\n",
    "    \n",
    "    raw_data = pd.read_csv(PATH_IN)\n",
    "    \n",
    "    raw_data['title'] = raw_data['title'].fillna('')\n",
    "    raw_data['txt_content'] = raw_data['txt_content'].fillna('')\n",
    "    raw_data['tag'] = raw_data['tag'].fillna('')\n",
    "    \n",
    "    text_source = raw_data['title'] + ' ' + \\\n",
    "                raw_data['txt_content'] + ' ' + \\\n",
    "                raw_data['tag'] \n",
    "    \n",
    "    text_source.to_csv(PATH_LDA + 'TEST_LDA_SOURCE.txt', encoding='utf-8', index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize( PATH_NORMAL ) :\n",
    "    \n",
    "    # feature1 : num of words in answer_content\n",
    "    f1 = pd.read_csv(PATH_NORMAL + 'f1.txt', names = ['index','len_answer_content'])\n",
    "\n",
    "    # feature2 : num of words in question_content\n",
    "    f2 = pd.read_csv(PATH_NORMAL + 'f2.txt', names = ['index','len_question_content'])\n",
    "    m = pd.merge(f1, f2, how='outer')\n",
    "    #print m\n",
    "\n",
    "    # feature3 : num of question tags \n",
    "    f3 = pd.read_csv(PATH_NORMAL + 'f3.txt', names = ['index', 'num_question_tags'])\n",
    "    m = pd.merge(m, f3, how='outer')\n",
    "\n",
    "    # feature4 : num of answers \n",
    "    f4 = pd.read_csv(PATH_NORMAL + 'f4.txt', names = ['index','num_answers'])\n",
    "    m = pd.merge(m, f4, how='outer')\n",
    "    #print m\n",
    "\n",
    "    # feature5 : num of agrees of user \n",
    "    f5 = pd.read_csv(PATH_NORMAL + 'f5.txt', names = ['index','num_user_agrees'])\n",
    "    m = pd.merge(m, f5, how='outer')\n",
    "\n",
    "    # feature6 : num of ans_y of user\n",
    "    f6 = pd.read_csv(PATH_NORMAL + 'f6.txt', names = ['index','num_ans_y'])\n",
    "    m = pd.merge(m, f6, how='outer')\n",
    "\n",
    "    # feature7 : num of Articles of user\n",
    "    f7 = pd.read_csv(PATH_NORMAL + 'f7.txt', names = ['index','num_user_articles'])\n",
    "    m = pd.merge(m, f7, how='outer')\n",
    "\n",
    "    # feature8 : num of Ask of user \n",
    "    f8 = pd.read_csv(PATH_NORMAL + 'f8.txt', names = ['index', 'num_user_ask'])\n",
    "    m = pd.merge(m, f8, how='outer')\n",
    "\n",
    "    # feature9 : num of Collection of user\n",
    "    f9 = pd.read_csv(PATH_NORMAL + 'f9.txt', names = ['index','num_user_collection'])\n",
    "    m = pd.merge(m, f9, how='outer')\n",
    "\n",
    "    # feature10 : num of edit log of user\n",
    "    f10 = pd.read_csv(PATH_NORMAL + 'f10.txt', names = ['index','num_user_editlog'])\n",
    "    m = pd.merge(m, f10, how='outer')\n",
    "\n",
    "    # feature11 : num of follower of user\n",
    "    f11 = pd.read_csv(PATH_NORMAL + 'f11.txt', names = ['index','num_user_follower'])\n",
    "    m = pd.merge(m, f11, how='outer')\n",
    "\n",
    "    # feature12 : num of thanks of user\n",
    "    f12 = pd.read_csv(PATH_NORMAL + 'f12.txt', names = ['index','num_user_thanks'])\n",
    "    m = pd.merge(m, f12, how='outer')\n",
    "\n",
    "    # feature13 : num of topic of user\n",
    "    f13 = pd.read_csv(PATH_NORMAL + 'f13.txt', names = ['index','num_user_topic'])\n",
    "    m = pd.merge(m, f13, how='outer')\n",
    "    \n",
    "    # feature14 : num of followee of user \n",
    "    f14 = pd.read_csv(PATH_NORMAL + 'f14.txt', names = ['index','num_user_followee'])\n",
    "    m = pd.merge(m, f14, how='outer')\n",
    "    \n",
    "    # feature15 : answerContent & questionContent overlap\n",
    "    f15 = pd.read_csv(PATH_NORMAL + 'f15.txt', names = ['index', 'ac_qc_overlap'])\n",
    "    m = pd.merge(m, f15, how = 'outer')\n",
    "\n",
    "    # feature16 : answerContent & questionTags overlap\n",
    "    f16 = pd.read_csv(PATH_NORMAL + 'f16.txt', names = ['index', 'ac_qt_overlap'])\n",
    "    m = pd.merge(m, f16, how = 'outer')\n",
    "    \n",
    "    #######################################################################\n",
    "    Index = m.ix[:,0] \n",
    "    M = m.ix[:,1:]\n",
    "\n",
    "    # M = (M - M.min()) / (M.max() - M.min())\n",
    "    M = (M - M.mean()) / M.std()\n",
    "    M['index'] = Index\n",
    "\n",
    "    M = M.drop('index', axis = 1)\n",
    "    M = M.fillna(0)\n",
    "\n",
    "    M.to_csv(PATH_NORMAL + 'Normal_Features.txt',  index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format S2V & Topic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_first_line(file_name) :\n",
    "    with open(file_name, 'r') as fin:\n",
    "        data = fin.read().splitlines(True)\n",
    "    with open(file_name, 'w') as fout:\n",
    "        fout.writelines(data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# USE S2V model to generate S2V features\n",
    "def generate_s2v_features() :\n",
    "    copyfile('./Features/Topic/TEST_LDA_SOURCE.txt', './Features/S2V/TEST_S2V_SOURCE.txt')\n",
    "    %run /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/S2V/demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_s2v_featues(PATH_S2V) :\n",
    "    s2v_list = []\n",
    "    for i in range(50) :\n",
    "        col_name = 's2v_' + str(i) \n",
    "        s2v_list.append(col_name)\n",
    "    # !!! before this , you should remove the first row of the Test_Source.txt.vec\n",
    "    remove_first_line(PATH_S2V + 'TEST_S2V_SOURCE.txt.vec')\n",
    "    total_s2v = pd.read_table(PATH_S2V + 'TEST_S2V_SOURCE.txt.vec', sep = ' ', names = s2v_list)\n",
    "    # test_s2v !!! very important : Normalization\n",
    "    total_s2v = (total_s2v - total_s2v.mean()) / total_s2v.std()\n",
    "    # total_s2v = (total_s2v - total_s2v.min()) / (total_s2v.max() - total_s2v.min())\n",
    "    # total_s2v # 11292 rows × 50 columns\n",
    "    total_s2v.to_csv(PATH_S2V + 'S2V_Features.csv', encoding='utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_topic_features():\n",
    "    %run /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Generate_Topic_Features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format the topic features\n",
    "def format_topic_features(PATH_LDA) :\n",
    "    \n",
    "    topic_list = []\n",
    "    for i in range(50) :\n",
    "        col_name = 'topic_' + str(i) \n",
    "        topic_list.append(col_name)\n",
    "\n",
    "    total_topic = pd.read_csv(PATH_LDA + 'Raw_Topic_Features.csv', names = topic_list, index_col=False)\n",
    "    # total_topic # 29385 rows × 50 columns\n",
    "    # test_topic !!! very important : Normalization by row\n",
    "    total_topic = total_topic.sub( total_topic.min(axis=1), axis=0 ) \n",
    "    total_topic = total_topic.div( total_topic.max(axis=1) - total_topic.min(axis=1), axis=0 )\n",
    "    # Normalize by column\n",
    "    total_topic = (total_topic - total_topic.mean()) / total_topic.std()\n",
    "    total_topic.to_csv(PATH_LDA + 'Topic_Features.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_features(PATH_NORMAL, PATH_S2V, PATH_LDA, PATH_FINAL, FILE) :\n",
    "    \n",
    "    Total_Normal = pd.read_csv(PATH_NORMAL + 'Normal_Features.txt')\n",
    "    Total_S2V = pd.read_csv(PATH_S2V + 'S2V_Features.csv')\n",
    "    Total_Topic = pd.read_csv(PATH_LDA + 'Topic_Features.csv')\n",
    "    \n",
    "    Total_Normal_S2V = pd.merge(Total_Normal, Total_S2V, left_index=True, right_index=True)\n",
    "    Total_Final = pd.merge(Total_Normal_S2V, Total_Topic, left_index=True, right_index=True)\n",
    "    \n",
    "    Total_Final.to_csv(PATH_FINAL + FILE, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LEVEL = './1000x5/'\n",
    "# LEVEL = './1000x6/'\n",
    "# LEVEL = './1000x7/'\n",
    "# LEVEL = './1000x8/'\n",
    "# LEVEL = './1000x9/'\n",
    "LEVEL = './1000x10/'\n",
    "\n",
    "PATH_NORMAL = './Features/Normal/'\n",
    "PATH_TEXT = './Features/Text/'\n",
    "PATH_LDA = './Features/Topic/'\n",
    "PATH_S2V = './Features/S2V/'\n",
    "\n",
    "PATH_FINAL_TEST_SET = LEVEL + 'Final_Test_Set/'\n",
    "PATH_FINAL_TEST_FEATURES = LEVEL + 'Final_Test_Features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.020872 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.020872 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./1000x9/Final_Test_Set/Final_Test_08.csv\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1207 lines in 0.013238 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1207 lines in 0.013238 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x9/Final_Test_Set/Final_Test_06.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.025784 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.025784 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1198 lines in 0.026086 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1198 lines in 0.026086 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Generate_Topic_Features.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
      "  tf = pd.read_table('/home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Raw_Topic_Features.csv', sep = ' |\"|\\[|\\]', header=None)\n",
      "/home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Generate_Topic_Features.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
      "  tf = pd.read_table('/home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Raw_Topic_Features.csv', sep = ' |\"|\\[|\\]', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x9/Final_Test_Set/Final_Test_05.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.019671 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.019671 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1167 lines in 0.014696 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1167 lines in 0.014696 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x9/Final_Test_Set/Final_Test_01.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.022891 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.022891 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1208 lines in 0.030221 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1208 lines in 0.030221 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Generate_Topic_Features.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
      "  tf = pd.read_table('/home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Raw_Topic_Features.csv', sep = ' |\"|\\[|\\]', header=None)\n",
      "/home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Generate_Topic_Features.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators; you can avoid this warning by specifying engine='python'.\n",
      "  tf = pd.read_table('/home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/Raw_Topic_Features.csv', sep = ' |\"|\\[|\\]', header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x9/Final_Test_Set/Final_Test_00.csv"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.024103 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.024103 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/zpgao/ML/Best_Answer/Zhihu/Step05_ranking_model/TEST/Features/Topic/TEST_LDA_SOURCE.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1217 lines in 0.038254 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1217 lines in 0.038254 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "./1000x9/Final_Test_Set/Final_Test_03.csv"
     ]
    }
   ],
   "source": [
    "for fname in os.listdir(PATH_FINAL_TEST_SET) :\n",
    "    if fname == '.' :\n",
    "        continue\n",
    "    if fname.startswith('Len') :\n",
    "        continue\n",
    "        \n",
    "    PATH_IN = os.path.join(PATH_FINAL_TEST_SET, fname)\n",
    "    print PATH_IN\n",
    "    \n",
    "    extract_normal_features(PATH_IN, PATH_NORMAL)\n",
    "    extract_text_features(PATH_IN, PATH_TEXT)\n",
    "    extract_overlap_features(PATH_TEXT, PATH_TEXT, PATH_NORMAL)\n",
    "    lda_source(PATH_IN, PATH_LDA)\n",
    "    normalize(PATH_NORMAL)\n",
    "    \n",
    "    generate_s2v_features()\n",
    "    format_s2v_featues(PATH_S2V)\n",
    "    \n",
    "    generate_topic_features()\n",
    "    format_topic_features(PATH_LDA)\n",
    "    \n",
    "    merge_features(PATH_NORMAL, PATH_S2V, PATH_LDA, PATH_FINAL_TEST_FEATURES, fname )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
